{
  "id": 722,
  "name": null,
  "url": "https:\/\/medium.com\/google-cloud\/app-engine-scheduler-settings-and-instance-count-4d1e669f33d5",
  "title": "TEST MOCK - App Engine, Scheduler settings, and instance count.",
  "icon": "https:\/cdn-images-1.medium.com\/fit\/c\/60\/60\/1*9UpQLq3zjGJ5x1Elvfh3iQ.png",
  "notes": null,
  "content": "<!DOCTYPE html><html><head><meta charset='utf-8>' \/><\/head><body><head><meta charset=\"utf-8&gt;\"><\/head>\n<body>\n<meta charset=\"utf-8&gt;\">\n<section name=\"e140\" class=\"section section--body section--first section--last\"><div class=\"section-divider\"><hr class=\"section-divider\"><\/div>\n<div class=\"section-content\">\n<div class=\"section-inner sectionLayout--fullWidth\"><figure name=\"3a2d\" id=\"3a2d\" class=\"graf graf--figure graf--layoutFillWidth graf--leading\"><div class=\"aspectRatioPlaceholder is-locked\">\n<div class=\"aspectRatioPlaceholder-fill\" style=\"padding-bottom: 14.799999999999999%;\"><\/div>\n<img class=\"graf-image\" data-image-id=\"1*i8gFMHNLtQJj-DnrepTSjw.jpeg\" data-width=\"2500\" data-height=\"370\" src=\"https:\/\/cdn-images-1.medium.com\/max\/2000\/1*i8gFMHNLtQJj-DnrepTSjw.jpeg\">\n<\/div><\/figure><\/div>\n<div class=\"section-inner sectionLayout--insetColumn\">\n<h1 name=\"0656\" id=\"0656\" class=\"graf graf--h3 graf-after--figure graf--title\">App Engine, Scheduler settings, and instance\u00a0count.<\/h1>\n<p name=\"1b42\" id=\"1b42\" class=\"graf graf--p graf-after--h3\">After <a href=\"https:\/medium.com\/@duhroach\/app-engine-and-the-connection-confusion-problem-d270b7465794\" data-href=\"https:\/\/medium.com\/@duhroach\/app-engine-and-the-connection-confusion-problem-d270b7465794\" class=\"markup--anchor markup--p-anchor\" target=\"_blank\">deferring a lot more fetches for the Cloud-Clouds-View application to the client<\/a>, I was able to help reduce the number of instances getting spun up significantly. But this started to make me worried, because I felt like I was just patching over the real problem. Truth be told, I still didn\u2019t know <em class=\"markup--em markup--p-em\">why<\/em> those instances were being spun up, or <em class=\"markup--em markup--p-em\">why<\/em> 4 seconds per request was having such an impact on the instance count.<\/p>\n<p name=\"f3b9\" id=\"f3b9\" class=\"graf graf--p graf-after--p\">Like most engineers, when I don\u2019t know something, it starts to gnaw at your brain until you finally get a chance to sit down dig into it. (<em class=\"markup--em markup--p-em\">I\u2019m sure there\u2019s a zombie joke in there somewhere..<\/em>) In my case, I decided to spin up my profiling code and spend a little time getting familiar with the <a href=\"https:\/cloud.google.com\/appengine\/docs\/python\/config\/appref\" data-href=\"https:\/\/cloud.google.com\/appengine\/docs\/python\/config\/appref\" class=\"markup--anchor markup--p-anchor\" rel=\"nofollow noopener\" target=\"_blank\">scheduler settings<\/a> inside App Engine.<\/p>\n<figure name=\"282d\" id=\"282d\" class=\"graf graf--figure graf--iframe graf-after--p\"><div class=\"aspectRatioPlaceholder is-locked\">\n<div class=\"aspectRatioPlaceholder-fill\" style=\"padding-bottom: 56.2%;\"><\/div>\n<div class=\"iframeContainer\"><iframe data-width=\"854\" data-height=\"480\" width=\"700\" height=\"393\" src=\"\/media\/6e9df870c559976529652f1a0c3331c8?postId=4d1e669f33d5\" data-media-id=\"6e9df870c559976529652f1a0c3331c8\" data-thumbnail=\"https:\/\/i.embed.ly\/1\/image?url=https%3A%2F%2Fi.ytimg.com%2Fvi%2FSH5xRgemOJs%2Fhqdefault.jpg&amp;key=4fce0568f2ce49e8b54624ef71a8a5bd\" allowfullscreen frameborder=\"0\"><\/iframe><\/div>\n<\/div>\n<figcaption class=\"imageCaption\">Too busy to read? Check out the TL;DR video above!<\/figcaption><\/figure><h3 name=\"8c3d\" id=\"8c3d\" class=\"graf graf--h3 graf-after--figure\">Background\u00a0: when does GAE spin up instances?<\/h3>\n<p name=\"6c6f\" id=\"6c6f\" class=\"graf graf--p graf-after--h3\">The App Engine serving algorithms are constantly deciding on whether it\u2019s better to queue a request or to spin up a new instance. This takes into account a significant number of factors, (such as queue depth, current <a href=\"https:\/en.wikipedia.org\/wiki\/Queries_per_second\" data-href=\"https:\/\/en.wikipedia.org\/wiki\/Queries_per_second\" class=\"markup--anchor markup--p-anchor\" rel=\"nofollow noopener\" target=\"_blank\">QPS<\/a>, avg. request latency etc) to decide if a new instance should be spun up. It\u2019s easy to talk about that for a single request but it gets much more complicated when considering high request load, or various types of request loads.<\/p>\n<figure name=\"bcf4\" id=\"bcf4\" class=\"graf graf--figure graf-after--p\"><div class=\"aspectRatioPlaceholder is-locked\" style=\"max-width: 488px; max-height: 261px;\">\n<div class=\"aspectRatioPlaceholder-fill\" style=\"padding-bottom: 53.5%;\"><\/div>\n<img class=\"graf-image\" data-image-id=\"1*TytPWaAVZOHn5M4pteasEA.png\" data-width=\"488\" data-height=\"261\" src=\"https:\/\/cdn-images-1.medium.com\/max\/800\/1*TytPWaAVZOHn5M4pteasEA.png\">\n<\/div><\/figure><p name=\"a989\" id=\"a989\" class=\"graf graf--p graf-after--figure\">With this in mind, there\u2019s four primary systems you need to consider in your configuration file, which can directly impact the decisions that GAE makes about spinning up new instances:<\/p>\n<ul class=\"postList\">\n<li name=\"8322\" id=\"8322\" class=\"graf graf--li graf-after--p\">Number of concurrent requests per instance<\/li>\n<li name=\"fe60\" id=\"fe60\" class=\"graf graf--li graf-after--li\">How long a request can sit in the work queue<\/li>\n<li name=\"14f9\" id=\"14f9\" class=\"graf graf--li graf-after--li\">If there\u2019s an idle instance available<\/li>\n<li name=\"a03c\" id=\"a03c\" class=\"graf graf--li graf-after--li\">What type of instance you\u2019re using.<\/li>\n<\/ul>\n<h3 name=\"57ae\" id=\"57ae\" class=\"graf graf--h3 graf-after--li\">A baseline<\/h3>\n<p name=\"84ee\" id=\"84ee\" class=\"graf graf--p graf-after--h3\">Let\u2019s dig into each one a bit to take a look at how it impacts your startup performance.<\/p>\n<p name=\"c6c1\" id=\"c6c1\" class=\"graf graf--p graf-after--p\">As a base line, here is 100k qps with the standard scheduler settings for 10 minute test with 800 concurrent connections:<\/p>\n<figure name=\"3f86\" id=\"3f86\" class=\"graf graf--figure graf-after--p\"><div class=\"aspectRatioPlaceholder is-locked\" style=\"max-width: 288px; max-height: 188px;\">\n<div class=\"aspectRatioPlaceholder-fill\" style=\"padding-bottom: 65.3%;\"><\/div>\n<img class=\"graf-image\" data-image-id=\"1*eF8nqt6-0vbHZsXZojkDew.png\" data-width=\"288\" data-height=\"188\" src=\"https:\/\/cdn-images-1.medium.com\/max\/800\/1*eF8nqt6-0vbHZsXZojkDew.png\">\n<\/div><\/figure><p name=\"c6dc\" id=\"c6dc\" class=\"graf graf--p graf-after--figure\">Note, in all the graphs below, we want to be watching the BLUE line; That\u2019s the count of # of instances. My server-code is pretty simple; I\u2019m creating a very isolated case of heavy workload so that I can test how these settings react when load is constantly 4 seconds:<\/p>\n<figure name=\"5ade\" id=\"5ade\" class=\"graf graf--figure graf-after--p\"><div class=\"aspectRatioPlaceholder is-locked\" style=\"max-width: 327px; max-height: 191px;\">\n<div class=\"aspectRatioPlaceholder-fill\" style=\"padding-bottom: 58.4%;\"><\/div>\n<img class=\"graf-image\" data-image-id=\"1*UfLKXwKYb0INpz-lOnkkeg.png\" data-width=\"327\" data-height=\"191\" src=\"https:\/\/cdn-images-1.medium.com\/max\/800\/1*UfLKXwKYb0INpz-lOnkkeg.png\">\n<\/div><\/figure><p name=\"eb39\" id=\"eb39\" class=\"graf graf--p graf-after--figure\">Obviously this is not a real-world scenario. If your server responses are taking 4 seconds, you\u2019ve got a serious amount of other things you need to take a look at and optimize. This does, however, allow me to isolate a specific variable, and see how the scheduler settings respond as a result. All tests below have this same server code, and the only thing that chances is a single scheduler setting.<\/p>\n<h3 name=\"6a6f\" id=\"6a6f\" class=\"graf graf--h3 graf-after--p\">Concurrent Requests<\/h3>\n<p name=\"de83\" id=\"de83\" class=\"graf graf--p graf-after--h3\">Probably one of the easiest knobs to turn is changing how many concurrent requests an Instance can handle at a single time. Once this number is eclipsed, the scheduler can spawn a new instance. The <strong class=\"markup--strong markup--p-strong\">max_concurrent_requests <\/strong>setting allows you to control this value (Default: 8, Maximum: 80).<\/p>\n<p name=\"904e\" id=\"904e\" class=\"graf graf--p graf-after--p\">Here\u2019s what it looks like when I change the <em class=\"markup--em markup--p-em\">max_conncurrent_requests<\/em> from 8(default) to 80 (10 minute duration):<\/p>\n<figure name=\"a030\" id=\"a030\" class=\"graf graf--figure graf-after--p\"><div class=\"aspectRatioPlaceholder is-locked\" style=\"max-width: 288px; max-height: 188px;\">\n<div class=\"aspectRatioPlaceholder-fill\" style=\"padding-bottom: 65.3%;\"><\/div>\n<img class=\"graf-image\" data-image-id=\"1*JTNrVaRLWXsx3V3z5oe4lA.png\" data-width=\"288\" data-height=\"188\" src=\"https:\/\/cdn-images-1.medium.com\/max\/800\/1*JTNrVaRLWXsx3V3z5oe4lA.png\">\n<\/div><\/figure><p name=\"7fa3\" id=\"7fa3\" class=\"graf graf--p graf-after--figure\">You can see that the number of create and active instances (blue line) dropped significantly from ~100 to ~20, which is important, since that means my bill has been cut by a significant amount.<\/p>\n<p name=\"0be2\" id=\"0be2\" class=\"graf graf--p graf-after--p\">The tradeoff here is straightforward. The higher this value, the less number of instances you need to spin up. Which can be very helpful (and a big cost savings) if the overhead of all those requests doesn\u2019t bog down the performance of your instance too much. Otherwise, you can fall into a trap<\/p>\n<p name=\"1e72\" id=\"1e72\" class=\"graf graf--p graf-after--p\">For example, if each request is spending time searching through image data, you may eclipse the memory of your instance since the machine may be doing 8x more work than normal.<\/p>\n<p name=\"fe71\" id=\"fe71\" class=\"graf graf--p graf-after--p\">Basically, if this number is too high, you might experience increased request latency. (so watch out!)<\/p>\n<h3 name=\"6845\" id=\"6845\" class=\"graf graf--h3 graf-after--p\">Pending Latency<\/h3>\n<p name=\"4315\" id=\"4315\" class=\"graf graf--p graf-after--h3\">When a request comes in, GAE\u2019s front-ends will place it in a queue until an instance becomes available to service the request. If there are no available instances waiting around, then GAE has to make a decision\u200a\u2014\u200aeither it waits for one of the instances to become available or it starts up a new instance. The values of min\/max pending latency directly control how long GAE will allow a request to wait in this queue before spinning up a new instance.<\/p>\n<p name=\"1af0\" id=\"1af0\" class=\"graf graf--p graf-after--p\">The higher the <a href=\"https:\/cloud.google.com\/appengine\/docs\/python\/config\/appref#min_pending_latency\" data-href=\"https:\/\/cloud.google.com\/appengine\/docs\/python\/config\/appref#min_pending_latency\" class=\"markup--anchor markup--p-anchor\" rel=\"nofollow noopener\" target=\"_blank\">Min Pending Latency<\/a> value, the longer a request will wait in the queue before triggering a new instance to be spawned. This results in less overall instances to be started (thus reducing the amount of total startup time you have to deal with) but will also result in higher user-visible latency during increased load. (BTW, the minimum value for this is 30ms\u00a0..)<\/p>\n<p name=\"7c77\" id=\"7c77\" class=\"graf graf--p graf-after--p\">The graph below shows the normal scheduler settings, but with min-pending-latency set to 6 seconds, instead of 30s (10 minutes):<\/p>\n<figure name=\"a766\" id=\"a766\" class=\"graf graf--figure graf-after--p\"><div class=\"aspectRatioPlaceholder is-locked\" style=\"max-width: 288px; max-height: 189px;\">\n<div class=\"aspectRatioPlaceholder-fill\" style=\"padding-bottom: 65.60000000000001%;\"><\/div>\n<img class=\"graf-image\" data-image-id=\"1*DDThQDDzJZCM0nEaq1Uz6w.png\" data-width=\"288\" data-height=\"189\" src=\"https:\/\/cdn-images-1.medium.com\/max\/800\/1*DDThQDDzJZCM0nEaq1Uz6w.png\">\n<\/div><\/figure><p name=\"fd5c\" id=\"fd5c\" class=\"graf graf--p graf-after--figure\">The result is that we spin up about 65 instances or so, over the 10 minutes, to handle the load that we were generating. Obviously this isn\u2019t an absolute win vs the max-concurrent-requests, but it does minimize the total number of instances vs. our default settings.<\/p>\n<p name=\"11e9\" id=\"11e9\" class=\"graf graf--p graf-after--p\"><a href=\"https:\/cloud.google.com\/appengine\/docs\/python\/config\/appref#max_pending_latency\" data-href=\"https:\/\/cloud.google.com\/appengine\/docs\/python\/config\/appref#max_pending_latency\" class=\"markup--anchor markup--p-anchor\" rel=\"nofollow noopener\" target=\"_blank\">Max Pending Latency<\/a>, on the other hand, is the time after which App Engine <strong class=\"markup--strong markup--p-strong\">must <\/strong>start up a new instance if a request has been waiting this long.<\/p>\n<p name=\"8ed6\" id=\"8ed6\" class=\"graf graf--p graf-after--p\">A low maximum results in starting new instances sooner for pending requests (resulting in more instances to be spawned, and more startup time to be incurred). Where a high maximum means users might wait longer for their requests to be served (if there are pending requests and no idle instances to serve them), but your application will cost less to run.<\/p>\n<p name=\"1f24\" id=\"1f24\" class=\"graf graf--p graf-after--p\">The graph below shows the normal scheduler settings, but with max-pending-latency set to 4 seconds (10 minutes):<\/p>\n<figure name=\"c402\" id=\"c402\" class=\"graf graf--figure graf-after--p\"><div class=\"aspectRatioPlaceholder is-locked\" style=\"max-width: 288px; max-height: 188px;\">\n<div class=\"aspectRatioPlaceholder-fill\" style=\"padding-bottom: 65.3%;\"><\/div>\n<img class=\"graf-image\" data-image-id=\"1*YX5e9MZShGnUzz17l1VhmA.png\" data-width=\"288\" data-height=\"188\" src=\"https:\/\/cdn-images-1.medium.com\/max\/800\/1*YX5e9MZShGnUzz17l1VhmA.png\">\n<\/div><\/figure><p name=\"f4a3\" id=\"f4a3\" class=\"graf graf--p graf-after--figure\">Since the server-work takes about 4 seconds, this one caused a massive spike in the # of instances that were spawned.<\/p>\n<p name=\"ae04\" id=\"ae04\" class=\"graf graf--p graf-after--p\">Just to sanity check how these two values work together, let\u2019s combine them, setting max to 8 seconds, and min to 6 seconds, and see how this influences our instance count:<\/p>\n<figure name=\"46a3\" id=\"46a3\" class=\"graf graf--figure graf-after--p\"><div class=\"aspectRatioPlaceholder is-locked\" style=\"max-width: 288px; max-height: 189px;\">\n<div class=\"aspectRatioPlaceholder-fill\" style=\"padding-bottom: 65.60000000000001%;\"><\/div>\n<img class=\"graf-image\" data-image-id=\"1*YIwM3N8780Exbbl41oIwYg.png\" data-width=\"288\" data-height=\"189\" src=\"https:\/\/cdn-images-1.medium.com\/max\/800\/1*YIwM3N8780Exbbl41oIwYg.png\">\n<\/div><\/figure><p name=\"bd25\" id=\"bd25\" class=\"graf graf--p graf-after--figure\">What was interesting about this test, was that there was a clear rise towards the end of it. We stayed at about 61 instances for most of the test, but jumped to about 75 towards the end.<\/p>\n<p name=\"5491\" id=\"5491\" class=\"graf graf--p graf-after--p\">For our particular test, these values didn\u2019t have much impact. In a real-world though, adjusting these values results in smoothing out some of the instance spikes that occur during heavy load, and balancing that against user perception and general cost to run your application. Under sustained heavy load, however, this may not be as impactful as other flags we might want to change.<\/p>\n<h3 name=\"eddb\" id=\"eddb\" class=\"graf graf--h3 graf-after--p\">Instance class<\/h3>\n<p name=\"8159\" id=\"8159\" class=\"graf graf--p graf-after--h3\">App engine has an excellent ability to provide support for instance types (see <a href=\"https:\/cloud.google.com\/appengine\/docs\/python\/an-overview-of-app-engine?csw=1#Python_Instance_scaling_and_class\" data-href=\"https:\/\/cloud.google.com\/appengine\/docs\/python\/an-overview-of-app-engine?csw=1#Python_Instance_scaling_and_class\" class=\"markup--anchor markup--p-anchor\" rel=\"nofollow noopener\" target=\"_blank\">your types and instance classes<\/a>), which you typically tune as a factor of trying to find the sweet spot between bandwidth, memory, and the number of instances you need to spin up.<\/p>\n<p name=\"adf7\" id=\"adf7\" class=\"graf graf--p graf-after--p\">There\u2019s two ways we can chart the impact of this flag. The first is <em class=\"markup--em markup--p-em\">how long it takes to start up<\/em> and the second is <em class=\"markup--em markup--p-em\">does it impact the number of instances?<\/em><\/p>\n<h3 name=\"b1b1\" id=\"b1b1\" class=\"graf graf--h3 graf-after--p\">Startup time based on instance\u00a0class<\/h3>\n<p name=\"a96a\" id=\"a96a\" class=\"graf graf--p graf-after--h3\">Check out the following graph, which charts instance class vs startup time for a basic hello-world application:<\/p>\n<figure name=\"87b5\" id=\"87b5\" class=\"graf graf--figure graf-after--p\"><div class=\"aspectRatioPlaceholder is-locked\" style=\"max-width: 585px; max-height: 358px;\">\n<div class=\"aspectRatioPlaceholder-fill\" style=\"padding-bottom: 61.199999999999996%;\"><\/div>\n<img class=\"graf-image\" data-image-id=\"1*3cu4zfVSLfQlxYgXXtyJ5Q.png\" data-width=\"585\" data-height=\"358\" src=\"https:\/\/cdn-images-1.medium.com\/max\/800\/1*3cu4zfVSLfQlxYgXXtyJ5Q.png\">\n<\/div><\/figure><p name=\"d455\" id=\"d455\" class=\"graf graf--p graf-after--figure\">It\u2019s worth noting that for the data above, instance startup time is properly <em class=\"markup--em markup--p-em\">fast<\/em> with most startups being &lt; 1 second, average. Note that this example is a bare-bones python app, that only returns \u201c<em class=\"markup--em markup--p-em\">hello world<\/em>\u201d. There can be some outliers though, so be warned that some instance types are more prone to hitting the outlier path than others<\/p>\n<p name=\"9143\" id=\"9143\" class=\"graf graf--p graf-after--p\">While it may seem direct to assume that the startup difference between B* and F* instances has to do with the machine type, my tests show that it\u2019s got more to do with provisioning than anything else. See, when you request a new instance, GAE has to go through and find a machine of that type, provision some space on it for your instance to run, and start the machinery<\/p>\n<h3 name=\"bc09\" id=\"bc09\" class=\"graf graf--h3 graf-after--p\">Instance count based on instance\u00a0class<\/h3>\n<p name=\"f523\" id=\"f523\" class=\"graf graf--p graf-after--h3\">The default value for instance_class is F1, which we have a graph for already. We can\u2019t test the B* classes, since those modify our scheduler settings (maybe that\u2019s a separate blog post), so let\u2019s test an F4 instance, and see how that changes our instance count (if at all):<\/p>\n<figure name=\"cff1\" id=\"cff1\" class=\"graf graf--figure graf-after--p\"><div class=\"aspectRatioPlaceholder is-locked\" style=\"max-width: 288px; max-height: 189px;\">\n<div class=\"aspectRatioPlaceholder-fill\" style=\"padding-bottom: 65.60000000000001%;\"><\/div>\n<img class=\"graf-image\" data-image-id=\"1*YIwM3N8780Exbbl41oIwYg.png\" data-width=\"288\" data-height=\"189\" src=\"https:\/\/cdn-images-1.medium.com\/max\/800\/1*YIwM3N8780Exbbl41oIwYg.png\">\n<\/div><\/figure><p name=\"cd65\" id=\"cd65\" class=\"graf graf--p graf-after--figure\">We can see that moving from F1 to F4 had some slight impact on the # of instances created. We at least had a smoother ramp up, and a sub 100 instance set for most of the time.<\/p>\n<h3 name=\"340f\" id=\"340f\" class=\"graf graf--h3 graf-after--p\">Side note\u00a0: fast machines are\u00a0fast.<\/h3>\n<p name=\"6394\" id=\"6394\" class=\"graf graf--p graf-after--h3\">There\u2019s many cases where the factor that causes GAE to spin up a new instance is due to machine limits. For example, a compute-heavy application could eclipse the total memory available for the instance type causing another instance to spin up.<\/p>\n<p name=\"e14b\" id=\"e14b\" class=\"graf graf--p graf-after--p\">A solution to this is to improve the instance size to a machine type that has more resources.<\/p>\n<p name=\"399c\" id=\"399c\" class=\"graf graf--p graf-after--p\">This may significantly increase the cost, per instance, but it can reduce the overall number of instances by a similar amount, which may end up as a cheaper solution.<\/p>\n<p name=\"2ae7\" id=\"2ae7\" class=\"graf graf--p graf-after--p\">As such, it\u2019s important to clearly adjust your instance type for the sake of scheduling, but also to reduce the number of spun-up-instances.<\/p>\n<h3 name=\"ee8e\" id=\"ee8e\" class=\"graf graf--h3 graf-after--p\">Putting it all\u00a0together<\/h3>\n<p name=\"8aac\" id=\"8aac\" class=\"graf graf--p graf-after--h3\">So, let\u2019s combine these settings together to figure out what\u2019s the best way to minimize our instance count, but not make user-perception fall through the floor. This means that for our 4 second block of work, we want the avg latency for a response to be as close to 4 seconds as possible.<\/p>\n<p name=\"7e23\" id=\"7e23\" class=\"graf graf--p graf-after--p\">To do this, let\u2019s set:<\/p>\n<p name=\"eb57\" id=\"eb57\" class=\"graf graf--p graf-after--p\"><strong class=\"markup--strong markup--p-strong\">instance_class = F4\u00a0; <\/strong>We know our work isn\u2019t susceptible to the performance of the Server we\u2019re running on, so a faster machine won\u2019t service our requests any faster. We choose F4 though, so that the max # of requests can be handled w\/o causing weird side-artifacts like out-of-memory.<\/p>\n<p name=\"6eb7\" id=\"6eb7\" class=\"graf graf--p graf-after--p\"><strong class=\"markup--strong markup--p-strong\">max_concurrent_requests = 80\u00a0; <\/strong>This lets\u2019 us maximize the server machine\u2019s potential.<\/p>\n<p name=\"9fc4\" id=\"9fc4\" class=\"graf graf--p graf-after--p\"><strong class=\"markup--strong markup--p-strong\">max_pending_latency = 8s\u00a0; <\/strong>If any request is waiting 8 seconds, we should start a new instance.<\/p>\n<p name=\"6a08\" id=\"6a08\" class=\"graf graf--p graf-after--p\"><strong class=\"markup--strong markup--p-strong\">min_pending_latency = 6s\u00a0; <\/strong>Don\u2019t spawn an instance unless we\u2019ve been waiting 6 seconds.<\/p>\n<p name=\"02f6\" id=\"02f6\" class=\"graf graf--p graf-after--p\">Given our same work load and test, let\u2019s see how we fair:<\/p>\n<figure name=\"cb2f\" id=\"cb2f\" class=\"graf graf--figure graf-after--p\"><div class=\"aspectRatioPlaceholder is-locked\" style=\"max-width: 348px; max-height: 202px;\">\n<div class=\"aspectRatioPlaceholder-fill\" style=\"padding-bottom: 57.99999999999999%;\"><\/div>\n<img class=\"graf-image\" data-image-id=\"1*nVWkeHsd8PxqbtU9bciw_Q.png\" data-width=\"348\" data-height=\"202\" src=\"https:\/\/cdn-images-1.medium.com\/max\/800\/1*nVWkeHsd8PxqbtU9bciw_Q.png\">\n<\/div><\/figure><p name=\"393d\" id=\"393d\" class=\"graf graf--p graf-after--figure\">We ended up with about 18 instance throughout the entire test, which is significantly lower than our other tests. On the other side of things, we need to consider how our settings have impacted latency for our test:<\/p>\n<figure name=\"d17d\" id=\"d17d\" class=\"graf graf--figure graf-after--p\"><div class=\"aspectRatioPlaceholder is-locked\" style=\"max-width: 232px; max-height: 183px;\">\n<div class=\"aspectRatioPlaceholder-fill\" style=\"padding-bottom: 78.9%;\"><\/div>\n<img class=\"graf-image\" data-image-id=\"1*fJMukVdp2RknolnOWEeLjQ.png\" data-width=\"232\" data-height=\"183\" src=\"https:\/\/cdn-images-1.medium.com\/max\/800\/1*fJMukVdp2RknolnOWEeLjQ.png\">\n<\/div><\/figure><p name=\"2262\" id=\"2262\" class=\"graf graf--p graf-after--figure\">Since we know our workload is exactly 4 seconds, we\u2019re seeing about +400ms latency being added to the requests (on average) due to all the other scheduler settings we have in place.<\/p>\n<p name=\"c87f\" id=\"c87f\" class=\"graf graf--p graf-after--p\">From here, we can start tweaking the numbers to make trade-offs between the # of instances we\u2019re willing to pay for, and the latency overhead it causes to our users. Which is a good spot to be.<\/p>\n<h3 name=\"16b3\" id=\"16b3\" class=\"graf graf--h3 graf-after--p\">Learnings &amp; take\u00a0away<\/h3>\n<p name=\"da34\" id=\"da34\" class=\"graf graf--p graf-after--h3\">Even though the load balances built into App Engine will handle the lion\u2019s share of dealing with scheduling and launching your instances, taking control of a number of components can help you hyper-optimize the system and get consistent, expected behavior for your app.<\/p>\n<p name=\"f53e\" id=\"f53e\" class=\"graf graf--p graf-after--p graf--trailing\">To be fair, it takes a bit to get all these things tested right, but optimizing instance count is highly worth it\u00a0;)<\/p>\n<\/div>\n<\/div><\/section>\n<\/body><\/body><\/html>",
  "description": "After deferring a lot more fetches for the Cloud-Clouds-View application to the client, I was able to help reduce the number of instances\u2026",
  "type": 1,
  "tags": [{
    "id": 433,
    "name": "startup",
    "color": "#95A5A6"
  }, {
    "id": 440,
    "name": "cli",
    "color": "#95A5A6"
  }, {
    "id": 474,
    "name": "server",
    "color": null
  }],
  "created_at": "2017-05-25T13:03:06+02:00",
  "updated_at": "2018-07-01T00:29:39+02:00",
  "preview_picture": "https:\/cdn-images-1.medium.com\/max\/1200\/1*i8gFMHNLtQJj-DnrepTSjw.jpeg",
  "reading_time": 9,
  "read": false,
  "website_info": {
    "author": "Colt McAnlis",
    "keywords": "",
    "description": "",
    "authorAvatar": "https:\/\/cdn-images-1.medium.com\/fit\/c\/60\/60\/0*bW2MamPPP1MeRjVP.jpg",
    "meta": {
      "og:title": "App Engine, Scheduler settings, and instance count.",
      "og:url": "https:\/\/medium.com\/google-cloud\/app-engine-scheduler-settings-and-instance-count-4d1e669f33d5",
      "og:image": "https:\/\/cdn-images-1.medium.com\/max\/1200\/1*i8gFMHNLtQJj-DnrepTSjw.jpeg",
      "fb:app_id": "542599432471018",
      "og:description": "After deferring a lot more fetches for the Cloud-Clouds-View application to the client, I was able to help reduce the number of instances\u2026",
      "author": "Colt McAnlis",
      "og:type": "article",
      "article:publisher": "https:\/\/www.facebook.com\/medium",
      "article:author": "https:\/\/medium.com\/@duhroach",
      "article:published_time": "2017-04-27T11:40:58.820Z",
      "og:site_name": "Medium",
      "al:ios:app_name": "Medium",
      "al:ios:app_store_id": "828256236",
      "al:android:package": "com.medium.reader",
      "al:android:app_name": "Medium",
      "al:ios:url": "medium:\/\/p\/4d1e669f33d5",
      "al:android:url": "medium:\/\/p\/4d1e669f33d5",
      "al:web:url": "https:\/\/medium.com\/google-cloud\/app-engine-scheduler-settings-and-instance-count-4d1e669f33d5"
    }
  },
  "crawler_status": 2
}